{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b26a377-83e4-4d8e-8517-59ddf81dd863",
   "metadata": {},
   "source": [
    "# L'observatoire du mot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78188147-b1c6-4cc0-94cf-6508e38a100c",
   "metadata": {},
   "source": [
    "à faire :\n",
    "\n",
    "- ~~créer un sous-dossier pour les fichiers csv ?~~\n",
    "- créer la vérification synonymes.py et mettre à jour le rapport\n",
    "- ajout d'un readme\n",
    "\n",
    "questions :\n",
    "\n",
    "- Le rapport Excel dynamique doit contenir le plus de filtres possibles ?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13f37669",
   "metadata": {},
   "source": [
    "Liens importants : \n",
    "\n",
    "- cours : https://github.com/surybang/Reporting_openpyxl\n",
    "- template structure projet : https://github.com/surybang/template_usid0f\n",
    "- lien du repository : https://github.com/Aminata-Dev/L-observatoire-du-mot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cb6d0a8-703a-40f7-8008-20c9527818e1",
   "metadata": {},
   "source": [
    "# Introduction – L’Observatoire du mot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cafd221e-bf86-475f-834c-1dfcb9cda2c5",
   "metadata": {},
   "source": [
    "Qu’est-ce qu’un mot ? On croit souvent que comprendre un mot, c’est être capable de le définir. Pourtant, dans le langage ordinaire, les mots ne sont pas d’abord des objets de définition : ce sont des outils d’usage.\n",
    "\n",
    "Prenons pour exemple le mot « seum ». Se trouve-t-il dans le dictionnaire ? Peut-être. Mais même lorsqu’il y figure, la définition n’en fait que documenter un usage préexistant. Ce mot, comme tant d’autres, est d’abord appris par immersion, en l’entendant dans des situations précises puis en l’utilisant soi-même. On comprend un mot parce qu’on sait quand et comment l’utiliser – non parce qu’on est capable d’en réciter une définition. Les mots que l’on connait ne sont pas forcément des mots que l’on sait définir mais plutôt des mots que l’on sait utiliser. Comme l’écrivait Wittgenstein dans *Le Cahier Bleu* à ce sujet : « Nous sommes incapables de circonscrire clairement les concepts que nous utilisons ; non parce que nous ne connaissons pas leur vraie définition, mais parce qu'ils n'ont pas de vraie \"définition\". Supposer qu'il y en a nécessairement serait comme supposer que, à chaque fois que des enfants jouent avec un ballon, ils jouent en respectant des règles strictes.» (Wittgenstein, *Le Cahier bleu*, [25-26], trad. M. Goldberg et J. Sackur, Gallimard, p. 67-69).\n",
    "\n",
    "*L’Observatoire du mot* naît de ce constat : un mot est bien plus qu’une entrée dans un dictionnaire. Comprendre un mot, c’est plonger dans son usage vivant, ses contextes, ses résonances culturelles et sociales. L’utilisateur ne reçoit pas un portrait figé du mot de son choix, mais une matière vivante de l’explorer. L’Observatoire du mot est un outil hybride entre **dictionnaire augmenté** et cartographie culturelle pour toute personne curieuse de comprendre non seulement ce que signifie un mot mais également de connaître sa place dans le monde.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08ab062f",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# Objectifs et ambitions de *l'Observatoire du mot*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "512d7d89-046b-47cc-b41b-a55791d3422a",
   "metadata": {},
   "source": [
    "Notre objectif est de créer un programme Python permettant à l’utilisateur de saisir un mot, puis de générer un fichier Excel structuré, interactif et partageable. Ce fichier sera produit à l’aide de la librairie openpyxl. Voici la forme du ficher Excel que nous souhaitons produire :\n",
    "\n",
    "![Schéma](docs\\schema_dashboard_observatoire_du_mot.png)\n",
    "\n",
    "Cette maquette de **tableau de bord** est inférée de la liste suivante présentant les « dimensions » d’un mot que nous aimerions explorer et visualiser :\n",
    "\n",
    "- **Dimension sémantique** : définitions / étymologie / synonymes / antonymes / citations célèbres / traductions.\n",
    "- **Dimension culturelle** : apparition du mot dans les titres d’œuvres d’art\n",
    "- **Dimension sociale** via les réseaux sociaux\n",
    "  - Récupérer les tops tweet/threads/commentaires/titres de vidéos/hashtags contenant le mot\n",
    "  - Co-occurrences : avec quels autres mots notre mot se retrouve-t-il le plus ? \n",
    "  - **Dimension statistique** : \n",
    "    - évolution de la fréquence d’apparition du mot\n",
    "\t- Donner un score de popularité (étoiles)\n",
    "- **Dimension médiatique** via médias.\n",
    "  - Retrouver les articles de l'actualité contenant ce mot.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35ade560",
   "metadata": {},
   "source": [
    "# Réflexions techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31df2ce9-6f24-4208-a072-92834f90ac57",
   "metadata": {},
   "source": [
    "Pour rendre l’expérience utilisateur fluide, nous envisageons d’ajouter une interface Streamlit dans laquelle l’utilisateur pourra entrer le mot à explorer.\n",
    "Le programme se chargera ensuite de lancer l’ensemble de la pipeline, sans nécessiter de modifications manuelles dans le code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa716d88-41e9-49ed-8d7c-e87fd81c96a3",
   "metadata": {},
   "source": [
    "## Les données du projet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97145b6e-0c05-4b5f-b885-ea85ed5598c6",
   "metadata": {},
   "source": [
    "Mais cela soulève une question centrale : comment structurer la récupération des données pour que tout fonctionne dans un ensemble cohérent ? En effet, nous devons collecter des données provenant de nombreuses **sources hétérogènes** pour donner vie à L’Observatoire du mot. Nous avons identifié quatre méthodes principales pour les collecter :\n",
    "\n",
    "- Le flux RSS qui est une manière standardisée de recevoir les derniers contenus publiés sur un site comme un fil d’actualité. Par exemple les flux RSS de journaux comme Le Monde ou Mediapart peuvent nous informer en temps réel des nouveaux articles contenant un mot. Le flux RSS permet de satisfaire la dimension médiatique et statistique.\n",
    "- L’utilisation d’API (Application Programming Interface), interfaces propres aux développeurs qui permettent de demander à des plateformes leurs données via un programme. Exemples : API de Genius, Spotify, IMDB, Reddit, YouTube, Twitter, forums… On demande par exemple \"tous les posts contenant le mot X\" et la plateforme renvoie une réponse structurée en JSON. L’utilisation d’API permet de satisfaire la dimension sociale, culturelle et statistique. L’utilisation d’API de grandes plateformes telles que citées ci-dessus donne également plus de crédibilité au projet car cette approche offre un comparatif qui suscitera l’intérêt de l’utilisateur et rend la dimension statistique plus fiable car ce sont des plateformes utilisées par des milliards d’utilisateurs.\n",
    "- Le scraping est une technique consistant à extraire automatiquement du contenu visible sur une page web. Nous pensons réaliser du scraping sur des pages web statiques comme Wikitionary, CNRTL, Gallica ou CRISCO pour satisfaire la dimension sémantique. Le scraping est un processus simple qui ne demande pas d’identifiants et de création d’applications comme le nécessite l’utilisation d’une API. \n",
    "- Nous pourrons également récupérer et exploiter des jeux de données existants récupérés sur internet (notamment Kaggle ou Projet Gutenberg), pour explorer la dimension culturelle (par exemple jeu de données référençant les titres d’œuvres les plus connus ou récupération de corpus littéraire) et sociale (par exemple top tweets ou forums archivés).\n",
    "\n",
    "Une fois les données collectées, un autre enjeu est de les structurer de manière cohérente malgré leur diversité. Chaque dimension identifiée (sémantique, culturelle, sociale, médiatique) devra respecter un schéma commun afin d’être aisément manipulable en Python et visualisable dans le fichier Excel final.\n",
    "\n",
    "Pour sécuriser notre projet et pouvoir tester l’observatoire sans être dépendants des aléas du scraping ou des limites d’API, nous prévoyons de **constituer un jeu de données de secours**. Ce fichier contiendra un échantillon représentatif pour chaque dimension (tweets les plus connus, titres d’œuvres célèbres, quelques articles de presse, …). Notre projet pourra donc être utilisé en mode déconnecté, ou en cas de saturation de services.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8afbf013",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## Interface streamlit\n",
    "\n",
    "Nous devons de passer par une interface Streamlit pour donner le choix de mot à l'utilisateur. Les questions qui se posent sont :\n",
    "\n",
    "- l'utilisateur doit il donner un mot existant (implique un fichier txt avec les mots français possibles)\n",
    "- faut il normaliser (oui),\n",
    "- gérer les bas de casse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14487db4",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# Dimensions lexicale"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bb8fed5",
   "metadata": {},
   "source": [
    "## Choix du mot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "530b2296",
   "metadata": {},
   "source": [
    "```python\n",
    "mot_entree = input(\"\\nEntre un mot de ton choix\\n@> \")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bca5afa",
   "metadata": {},
   "source": [
    "## Synonymes\n",
    "\n",
    "NP Louis : Pourquoi et comment le choix de ce site \n",
    "Ce site est simple à scraper, seule l'information essentielle y est affichée.\n",
    "\n",
    "Pour preuve, il suffit d'ajouter le mot du choix à l'url (et pas un code-index compliqué) pour accéder à la bonne page\n",
    "```python\n",
    "url = 'https://crisco4.unicaen.fr/des/synonymes/' + mot_entree\n",
    "```\n",
    "et commencer à parser le contenu html de la page\n",
    "```python\n",
    "page = requests.get(url)\n",
    "\n",
    "#bs4 permet de parser le contenu html d'une page \n",
    "soupe = BeautifulSoup(page.text, features=\"html.parser\")\n",
    "```\n",
    "\n",
    "Nous souhaitons obtenir chaque synonyme associé au mot d'entrée et le score de popularité associé au synonyme. Ces éléments se présentent sous la forme suivante :\n",
    "\n",
    "![Tableau à scraper](docs/synonymes/tableau_synonymes_alambique.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "004cb606",
   "metadata": {},
   "source": [
    "![HTML derrière le tableau à scraper](docs/synonymes/inspection_tableau_synonymes_alambique.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c3633a7",
   "metadata": {},
   "source": [
    "\n",
    "Le tableau contient toutes les informations dont nous avons besoin pour commencer à scraper. Nous ciblons d'abord la balise `<table>` et nous recherchons le contenu des balises `<a href>` qui contiennent les synonymes. Une simple recherche du contenu des balises `<a href>` ira chercher tous les synonymes à l'ecran ailleurs que dans le tableau d'intérêt identifié plus haut et la somme des synonmymes sera supérieur au nombre de lignes du tableau. Nous avons donc adapté notre code de la manière suivante.\n",
    "\n",
    "```python\n",
    "synonymes = []\n",
    "\n",
    "#modèle : <a href=\"/des/synonymes/balle\">balle</a>\n",
    "for balise_a in soupe.find('table').find_all('a', href=True):\n",
    "    if \"/des/synonymes/\" in balise_a['href']:\n",
    "        synonyme = (balise_a.text).replace('\\xa0', '')\n",
    "        #print(synonyme)\n",
    "        synonymes.append(synonyme)\n",
    "#print(synonymes)\n",
    "```\n",
    "\n",
    "Pour éviter ce problème d'obtenir plus de synonymes et être certains de notrescraping (certains mots peuvent avoir une cinquantaine de synonymes recensés), nous effectuons une assertion pour vérifier que le nombre de synonymes trouvés et stockés dans la variable `synonymes` est bien le même que celui affiché sur site.\n",
    "\n",
    "```python\n",
    "NP\n",
    "```\n",
    "\n",
    "Ensuite nous observons que bl'indication de taille de la barre affichée `width` nous permet d'obtenir l'indicateur de score de proximité. Voici le modèle d'une balise contenant l'information de taille de la barre : `<hr style=\"height:6px;width:14px;color:#4040C0;background-color:#4040C0;text-align:left;margin-left:0\">`. Nous utilisons donc une expression régulière afin de récupérer cette information et l'utiliser dans notre diagramme en bâtons.\n",
    "`r'width:(\\d+)px'`\n",
    "\n",
    "(\\d+): Les parenthèses () sont utilisées pour capturer un groupe. \\d correspond à n'importe quel chiffre (0-9), et le + signifie \"un ou plusieurs\". Donc, \\d+ correspond à une séquence d'un ou plusieurs chiffres. Cette partie de l'expression régulière capture la valeur numérique de la largeur.\n",
    "\n",
    "```python\n",
    "#modèle : <hr style=\"height:6px;width:14px;color:#4040C0;background-color:#4040C0;text-align:left;margin-left:0\">\n",
    "\n",
    "import re\n",
    "tailles_barre = []\n",
    "\n",
    "for hr in soupe.find_all('hr', style=True):\n",
    "    #print(hr[\"style\"])\n",
    "    \n",
    "    #extraction du nombre après \"width:\"\n",
    "    match = re.search(r'width:(\\d+)px', hr[\"style\"])\n",
    "\n",
    "    if match:\n",
    "        width = int(match.group(1))\n",
    "        #print(width)\n",
    "    \n",
    "    tailles_barre.append(width)\n",
    "```\n",
    "\n",
    "Enfin, nous nous assurons que le nombre de score de proximité est bien le même que le nombre de synonyme trouvé grâce à l'instruction `assert len(tailles_barre) == len(synonymes)`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4748c85",
   "metadata": {},
   "source": [
    "Nous avons besoin de sauvegarder nos résultats afin de l'exploiter avec opepyxl. Nous décidons que chaque ficher tel que `synonymes.py` doit générer un fichier csv prêt à l'emploi pour l'utilisation par openpyxl.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7e32e36",
   "metadata": {},
   "source": [
    "\n",
    "## Exportation CSV\n",
    "\n",
    "### Questions d'optimisations\n",
    "La question qui se pose est la suivante : vaut-il mieux utiliser **la librairie pandas ou la librarie csv** ? L'utilisation de la librarie csv disponible par défaut dans python permet de garder le programme ultra léger et plus rapide. En effet, la librarie pandas est plus lourde car elle inclut tout un écosystème data (ce qui implique des dépendances externes). Ces quelques milisecondes gagnées en utilisant une librarire ou une autre peuvent être cruciales si notre programme principal de génération du tableau de bord fait appel à plusieurs modules de scraping, requête API et flux RSS à la fois. Nous retenons tout de même la librairie pandas pour éviter de devoir inspecter le document à la main lorsque nous aurons à travailler avec données volumineuses comme les titres d'oeuvres d'art.\n",
    "\n",
    "### Demonstration\n",
    "Nous créons donc un ficher exportations_csv chargé d'exporter un dictionnaire python quelconque contenant les données de la manière suivante\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def exporter_donnees_csv(donnees: dict[str, list], nom_fichier: str, index=False) -> None:\n",
    "    \"\"\"\n",
    "    Exporte un dictionnaire de données en fichier CSV.\n",
    "    \n",
    "    - donnees : dictionnaire {nom_colonne: liste_valeurs}\n",
    "    - nom_fichier : nom du fichier csv à créer (ex: \"synonymes.csv\")\n",
    "    \"\"\"\n",
    "\n",
    "    #création du chemin où sont stockés les données...\n",
    "    chemin_dossier = 'data'\n",
    "    chemin_complet = os.path.join(chemin_dossier, nom_fichier)\n",
    "    #... et création du sous-dossier data s'il n'existe pas\n",
    "    os.makedirs(chemin_dossier, exist_ok=True)\n",
    "\n",
    "    df = pd.DataFrame(donnees)\n",
    "    df.to_csv(chemin_complet, index=index)\n",
    "```\n",
    "\n",
    "Voici un exemple d'exportation de données dans un format csv prêt à l'emploi pour openpyxl\n",
    "\n",
    "```python\n",
    "from exportation_csv import exporter_donnees_csv\n",
    "\n",
    "synonymes_csv = {\n",
    "    \"mot\": [mot_entree] *len(synonymes),\n",
    "    \"synonyme\": synonymes,\n",
    "    \"score_proximite_mot\": tailles_barre\n",
    "}\n",
    "\n",
    "exporter_donnees_csv(synonymes_csv, \"synonymes.csv\")\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
